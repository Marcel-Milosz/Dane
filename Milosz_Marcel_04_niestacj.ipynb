{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Milosz_Marcel_04_niestacj.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPAAs42MoDmCSd2+EjJTDnk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marcel-Milosz/Dane/blob/Code-Review/Milosz_Marcel_04_niestacj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Relm7ypHnRQ"
      },
      "source": [
        "!pip install hpsklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m46u0oQrFlzQ",
        "outputId": "46a6beb8-22e9-41ae-f0e4-3387bd8c6601"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from hpsklearn import HyperoptEstimator\n",
        "from hpsklearn import any_classifier\n",
        "from hpsklearn import any_preprocessing\n",
        "from hyperopt import tpe\n",
        "\n",
        "# Getting wine data (features and target)\n",
        "wine = load_wine()\n",
        "features = wine['data']\n",
        "target = wine['target']\n",
        "\n",
        "logreg = LogisticRegression(solver=\"liblinear\")   # Regression \n",
        "\n",
        "penalty = [\"l1\", \"l2\"]  # Penalty array\n",
        "\n",
        "C = np.logspace(0, 4, 1000) # C parameter\n",
        "\n",
        "hparam = dict(C=C, penalty=penalty)  # hyperparameters\n",
        "\n",
        "def GridSearch():\n",
        "\n",
        "  gridsearch = GridSearchCV(logreg, hparam, cv=5, verbose=2, n_jobs=-1)  \n",
        "  model = gridsearch.fit(features, target)\n",
        "\n",
        "  print(model.best_estimator_.get_params()['penalty'])\n",
        "  print(model.best_estimator_.get_params()['C'])\n",
        "\n",
        "def RandomizedSearch():\n",
        "\n",
        "  randomizedsearch = RandomizedSearchCV(logreg, hparam, random_state=1, n_iter=1000, cv=5, verbose=0, n_jobs=-1)\n",
        "  model = randomizedsearch.fit(features, target)\n",
        "\n",
        "  print(model.best_estimator_.get_params()['penalty'])\n",
        "  print(model.best_estimator_.get_params()['C'])\n",
        "\n",
        "def BestAlgorithm():\n",
        "\n",
        "  pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
        "\n",
        "  search_space = [\n",
        "      {\"classifier\": [logreg], \"classifier__penalty\": [\"l1\", \"l2\"], \"classifier__C\": np.logspace(0, 4, 10)},\n",
        "      {\"classifier\": [RandomForestClassifier()], \"classifier__n_estimators\": [10, 50, 100], \"classifier__max_features\": [1, 2, 3]},\n",
        "      {\"classifier\": [KNeighborsClassifier()], \"classifier__n_neighbors\": range(1, 10, 1), \"classifier__leaf_size\": [30, 60, 90]}\n",
        "  ]\n",
        "\n",
        "  gridsearch = GridSearchCV(pipe, search_space, cv=5, verbose=1, n_jobs=-1)\n",
        "  model = gridsearch.fit(features, target)\n",
        "  print(model.best_estimator_.get_params()[\"classifier\"])\n",
        "\n",
        "\n",
        "def Hyperopt():\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=42)\n",
        "  \n",
        "  model = HyperoptEstimator(classifier=any_classifier(\"cla\"), preprocessing=any_preprocessing(\"pre\"), algo=tpe.suggest, max_evals=20, trial_timeout=30, n_jobs=-1)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  accuracy = model.score(X_test, y_test)\n",
        "  print(f\"Model accuracy: {accuracy}\")\n",
        "  print(model.best_model())\n",
        "\n",
        "print(\"\\nGridSearch function: \")\n",
        "GridSearch()\n",
        "\n",
        "print(\"\\nRandomizedSearch function: \")\n",
        "RandomizedSearch()\n",
        "\n",
        "print(\"\\nBest algorithm: \")\n",
        "BestAlgorithm()\n",
        "\n",
        "print(\"\\n\\nHyperopt: \")\n",
        "# Hyperopt()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "GridSearch function: \n",
            "Fitting 5 folds for each of 2000 candidates, totalling 10000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 246 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done 2182 tasks      | elapsed:   19.7s\n",
            "[Parallel(n_jobs=-1)]: Done 5430 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 9958 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  1.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "l2\n",
            "1.6758078645307677\n",
            "\n",
            "RandomizedSearch function: \n",
            "l2\n",
            "2.887090917359236\n",
            "\n",
            "Best algorithm: \n",
            "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:    4.2s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features=1,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "\n",
            "\n",
            "Hyperopt: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:    4.6s finished\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}